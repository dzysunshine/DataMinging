{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （特征工程2 - 特征选择） - 分别用IV值和随机森林挑选特征，再构建模型，进行模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在二分类问题中，IV值（Information Value）主要用来对输入变量进行编码和预测能力评估。\n",
    "\n",
    "一般选择中等和强预测能力的变量用于模型开发，一些学派也只提倡具有中等IV值的变量来进行模型开发。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV值主要用于特征选择，如果想对变量的预测能力进行排序，可以按 IV 值从高到低筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 导入数据\n",
    "data = pd.read_csv('data_2.csv')\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# 载入特征\n",
    "with open('feature.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "# 提取标签\n",
    "y = data.status\n",
    "\n",
    "# 划分训练集测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=2333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性能评估\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "def model_metrics(clf, X_train, X_test, y_train, y_test):\n",
    "    # 预测\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    \n",
    "    y_train_proba = clf.predict_proba(X_train)[:,1]\n",
    "    y_test_proba = clf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # 准确率\n",
    "    print('[准确率]', end = ' ')\n",
    "    print('训练集：', '%.4f'%accuracy_score(y_train, y_train_pred), end = ' ')\n",
    "    print('测试集：', '%.4f'%accuracy_score(y_test, y_test_pred))\n",
    "    \n",
    "    # auc取值：用roc_auc_score或auc\n",
    "    print('[auc值]', end = ' ')\n",
    "    print('训练集：', '%.4f'%roc_auc_score(y_train, y_train_proba), end = ' ')\n",
    "    print('测试集：', '%.4f'%roc_auc_score(y_test, y_test_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. IV值进行特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stats.scoreatpercentile(x, 50) # 得到x在50%处的数值\n",
    "\n",
    "np.in1d(B,A) # 在序列B中寻找与序列A相同的值，并返回一逻辑值（True,False）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理上述特征时, 遇到了IV的极端情况, 响应数为0或未响应数为0。\n",
    "\n",
    "为简单起见, 我们在代码中对极端值进行平滑处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "def woe(X, y, event=1):  \n",
    "    res_woe = []\n",
    "    iv_dict = {}\n",
    "    for feature in X.columns:\n",
    "        x = X[feature].values\n",
    "        # 1) 连续特征离散化\n",
    "        if type_of_target(x) == 'continuous':\n",
    "            x = discrete(x)\n",
    "        # 2) 计算该特征的woe和iv\n",
    "        # woe_dict, iv = woe_single_x(x, y, feature, event)\n",
    "        woe_dict, iv = woe_single_x(x, y, feature, event)\n",
    "        iv_dict[feature] = iv\n",
    "        res_woe.append(woe_dict) \n",
    "        \n",
    "    return iv_dict\n",
    "        \n",
    "def discrete(x):\n",
    "    # 使用5等分离散化特征\n",
    "    res = np.zeros(x.shape)\n",
    "    for i in range(5):\n",
    "        point1 = stats.scoreatpercentile(x, i * 20)\n",
    "        point2 = stats.scoreatpercentile(x, (i + 1) * 20)\n",
    "        x1 = x[np.where((x >= point1) & (x <= point2))]\n",
    "        mask = np.in1d(x, x1)\n",
    "        res[mask] = i + 1    # 将[i, i+1]块内的值标记成i+1\n",
    "    return res\n",
    "\n",
    "def woe_single_x(x, y, feature,event = 1):\n",
    "    # event代表预测正例的标签\n",
    "    event_total = sum(y == event)\n",
    "    non_event_total = y.shape[-1] - event_total\n",
    "    \n",
    "    iv = 0\n",
    "    woe_dict = {}\n",
    "    for x1 in set(x):    # 遍历各个块\n",
    "        y1 = y.reindex(np.where(x == x1)[0])\n",
    "        event_count = sum(y1 == event)\n",
    "        non_event_count = y1.shape[-1] - event_count\n",
    "        rate_event = event_count / event_total    \n",
    "        rate_non_event = non_event_count / non_event_total\n",
    "        \n",
    "        if rate_event == 0:\n",
    "            rate_event = 0.0001\n",
    "            # woei = -20\n",
    "        elif rate_non_event == 0:\n",
    "            rate_non_event = 0.0001\n",
    "            # woei = 20\n",
    "        woei = math.log(rate_event / rate_non_event)\n",
    "        woe_dict[x1] = woei\n",
    "        iv += (rate_event - rate_non_event) * woei\n",
    "    return woe_dict, iv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loans_latest_time_month', 0.23536009610676906),\n",
       " ('latest_query_time_weekday', 0.22341492175897784),\n",
       " ('latest_query_time_month', 0.22281703262580477),\n",
       " ('avg_consume_less_12_valid_month', 0.22239702810015521),\n",
       " ('first_transaction_time_weekday', 0.22040179517292707),\n",
       " ('reg_preference_for_trad', 0.2177870321526657),\n",
       " ('first_transaction_time_month', 0.21771183020755758),\n",
       " ('loans_cash_count', 0.21757359026066675),\n",
       " ('loans_org_count_current', 0.21757359026066675),\n",
       " ('history_suc_fee', 0.21659344037069103),\n",
       " ('loans_latest_day', 0.2164524029470496),\n",
       " ('loans_latest_time_weekday', 0.21550477980307856),\n",
       " ('latest_query_day', 0.21265811933623147),\n",
       " ('apply_credibility', 0.21236457565886172),\n",
       " ('trans_fail_top_count_enum_last_12_month', 0.2123504757203065),\n",
       " ('loans_product_count', 0.21194036422792928),\n",
       " ('loans_score', 0.21110907500076165),\n",
       " ('transd_mcc', 0.211048655685347),\n",
       " ('latest_three_month_loan', 0.21045694705509993),\n",
       " ('consfin_max_limit', 0.20992973971407752),\n",
       " ('consfin_credibility', 0.20973037158267904),\n",
       " ('latest_six_month_apply', 0.20943309101040308),\n",
       " ('loans_credibility_behavior', 0.20913259783498153),\n",
       " ('trans_fail_top_count_enum_last_6_month', 0.20879998791457863),\n",
       " ('loans_count', 0.20874971350331598),\n",
       " ('loans_settle_count', 0.2087212729473784),\n",
       " ('loans_overdue_count', 0.20845354896315071),\n",
       " ('consume_mini_time_last_1_month', 0.2076501423520914),\n",
       " ('historical_trans_amount', 0.2075080060278298),\n",
       " ('loans_org_count_behavior', 0.207484806762421),\n",
       " ('trans_amount_increase_rate_lately', 0.20702655677398674),\n",
       " ('query_finance_count', 0.20701327036924683),\n",
       " ('regional_mobility', 0.20654433409120623),\n",
       " ('latest_one_month_apply', 0.20652947633455448),\n",
       " ('trans_top_time_last_6_month', 0.2063985252397822),\n",
       " ('consfin_avg_limit', 0.20635049882515172),\n",
       " ('latest_six_month_loan', 0.20618043526436647),\n",
       " ('history_fail_fee', 0.20568666939352037),\n",
       " ('consfin_org_count_behavior', 0.20557154838757058),\n",
       " ('consfin_org_count_current', 0.20557154838757058),\n",
       " ('max_consume_count_later_6_month', 0.20546417446701087),\n",
       " ('loans_credibility_limit', 0.20533354487764222),\n",
       " ('first_transaction_day', 0.2052113753685888),\n",
       " ('first_transaction_time_year', 0.2046103090844746),\n",
       " ('query_cash_count', 0.2040658929496973),\n",
       " ('consfin_product_count', 0.20286887692642128),\n",
       " ('trans_activity_day', 0.20286597288594313),\n",
       " ('abs', 0.20272501154455297),\n",
       " ('trans_top_time_last_1_month', 0.2024095047823023),\n",
       " ('loans_credit_limit', 0.2024080356076561),\n",
       " ('apply_score', 0.20193079923229462),\n",
       " ('pawns_auctions_trusts_consume_last_1_month', 0.2017986145111209),\n",
       " ('trans_amount_3_month', 0.2012133745632707),\n",
       " ('query_org_count', 0.20111878037869466),\n",
       " ('loans_max_limit', 0.20102564665960093),\n",
       " ('historical_trans_day', 0.20079177389994785),\n",
       " ('trans_days_interval_filter', 0.20078178097293514),\n",
       " ('repayment_capability', 0.2006717198752902),\n",
       " ('trans_activity_month', 0.20061987700620626),\n",
       " ('consume_top_time_last_6_month', 0.20011434179160154),\n",
       " ('consume_top_time_last_1_month', 0.19987570921661652),\n",
       " ('avg_price_last_12_month', 0.19981081148969726),\n",
       " ('trans_fail_top_count_enum_last_1_month', 0.19966654427630234),\n",
       " ('number_of_trans_from_2011', 0.19964085140257198),\n",
       " ('loans_latest_time_year', 0.19963733017168203),\n",
       " ('loans_avg_limit', 0.19929828479259548),\n",
       " ('middle_volume_percent', 0.1987889286921986),\n",
       " ('loans_long_time', 0.1984601684347102),\n",
       " ('top_trans_count_last_1_month', 0.1982985665309038),\n",
       " ('take_amount_in_later_12_month_highest', 0.19825395861487763),\n",
       " ('consfin_credit_limit', 0.19817062884260578),\n",
       " ('query_sum_count', 0.1981147972726225),\n",
       " ('trans_day_last_12_month', 0.19802360655981613),\n",
       " ('latest_query_time_year', 0.19785800765281902),\n",
       " ('pawns_auctions_trusts_consume_last_6_month', 0.19775095600799367),\n",
       " ('cross_consume_count_last_1_month', 0.19766828036799108),\n",
       " ('max_cumulative_consume_later_1_month', 0.1976085708621358),\n",
       " ('trans_days_interval', 0.19752369963186445),\n",
       " ('latest_three_month_apply', 0.1975056731962344),\n",
       " ('student_feature', 0.1973961955679536),\n",
       " ('latest_one_month_loan', 0.19737896713498773),\n",
       " ('rank_trad_1_month', 0.19690523890879305),\n",
       " ('latest_one_month_suc', 0.19636285038441267),\n",
       " ('latest_one_month_fail', 0.19615676727445658),\n",
       " ('is_high_user', 0.19615128275454694),\n",
       " ('railway_consume_count_last_12_month', 0.1961481366164229),\n",
       " ('jewelry_consume_count_last_6_month', 0.1961481366164229)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "iv_dict = woe(X_train, y_train)\n",
    "iv = sorted(iv_dict.items(), key = lambda x:x[1],reverse = True)\n",
    "iv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 随机森林挑选特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先网格调参，求得模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "袋外分数： 0.7333934475503456\n",
      "[准确率] 训练集： 0.9802 测试集： 0.7730\n",
      "[auc值] 训练集： 0.9995 测试集： 0.7201\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 观察默认参数的性能\n",
    "rf0 = RandomForestClassifier(oob_score=True, random_state=2333)\n",
    "rf0.fit(X_train, y_train)\n",
    "print('袋外分数：', rf0.oob_score_)\n",
    "model_metrics(rf0, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 180}, 0.7841192009211578)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网格法调参, 步骤省略...\n",
    "\n",
    "param_test = {'n_estimators':range(20,200,20)}\n",
    "# param_test = {'max_depth':range(3,14,2), 'min_samples_split':range(50,201,20)}\n",
    "# param_test = {'min_samples_split':range(10,100,20), 'min_samples_leaf':range(10,60,10)}\n",
    "# param_test = {'max_features':range(3,17,2)}\n",
    "gsearch = GridSearchCV(estimator = RandomForestClassifier(n_estimators=120, max_depth=9, min_samples_split=50, \n",
    "                                                          min_samples_leaf=20, max_features = 9,random_state=2333), \n",
    "                       param_grid = param_test, scoring='roc_auc', cv=5)\n",
    "\n",
    "gsearch.fit(X_train, y_train)\n",
    "# gsearch.grid_scores_, \n",
    "gsearch.best_params_, gsearch.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终参数及性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "袋外分数： 0.7844905320108205\n",
      "[准确率] 训练集： 0.8115 测试集： 0.7912\n",
      "[auc值] 训练集： 0.8949 测试集： 0.7922\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=120, max_depth=9, min_samples_split=50,\n",
    "                            min_samples_leaf=20, max_features = 9,oob_score=True, random_state=2333)\n",
    "rf.fit(X_train, y_train)\n",
    "print('袋外分数：', rf.oob_score_)\n",
    "model_metrics(rf, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 平均不纯度减少 mean decrease impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于每颗树，按照impurity（此处是gini指数 ）给特征排序，然后整个森林取平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "feature_impotance1 = sorted(zip(map(lambda x: '%.4f'%x, rf.feature_importances_), list(X_train.columns)), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.1231', 'trans_fail_top_count_enum_last_1_month'),\n",
       " ('0.0801', 'history_fail_fee'),\n",
       " ('0.0737', 'loans_score'),\n",
       " ('0.0672', 'apply_score'),\n",
       " ('0.0667', 'latest_one_month_fail'),\n",
       " ('0.0416', 'loans_overdue_count'),\n",
       " ('0.0320', 'trans_fail_top_count_enum_last_12_month'),\n",
       " ('0.0250', 'trans_fail_top_count_enum_last_6_month'),\n",
       " ('0.0208', 'trans_day_last_12_month'),\n",
       " ('0.0167', 'rank_trad_1_month')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_impotance1[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 平均精确率减少 Mean decrease accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打乱每个特征的特征值顺序，并且度量顺序变动对模型的精确率的影响。（也可以measure每个特征加躁，看对结果的准确率的影响。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "\n",
    "scores = defaultdict(list)\n",
    "rs = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "for train_idx, test_idx in rs.split(X_train):\n",
    "    x_train, x_test = X_train.values[train_idx], X_train.values[test_idx]\n",
    "    Y_train, Y_test = y_train.values[train_idx], y_train.values[test_idx]\n",
    "    r = rf.fit(x_train, Y_train)\n",
    "    acc = accuracy_score(Y_test, rf.predict(x_test))\n",
    "    for i in range(x_train.shape[1]):\n",
    "        X_t = x_test.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        shuff_acc = accuracy_score(Y_test, rf.predict(X_t))\n",
    "        scores[X_train.columns[i]].append((acc - shuff_acc) / acc)\n",
    "        \n",
    "feature_impotance2=sorted([('%.4f'%np.mean(score), feat) for feat, score in scores.items()], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.0184', 'history_fail_fee'),\n",
       " ('0.0171', 'trans_fail_top_count_enum_last_1_month'),\n",
       " ('0.0120', 'latest_one_month_fail'),\n",
       " ('0.0089', 'apply_score'),\n",
       " ('0.0087', 'loans_score'),\n",
       " ('0.0076', 'loans_overdue_count'),\n",
       " ('0.0056', 'trans_fail_top_count_enum_last_6_month'),\n",
       " ('0.0043', 'latest_one_month_suc'),\n",
       " ('0.0026', 'rank_trad_1_month'),\n",
       " ('0.0023', 'latest_query_day')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_impotance2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 综合挑选特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_transaction_time_year 0.2046103090844746\n",
      "first_transaction_time_weekday 0.22040179517292707\n",
      "latest_query_time_year 0.19785800765281902\n",
      "latest_query_time_month 0.22281703262580477\n",
      "loans_latest_time_year 0.19963733017168203\n",
      "loans_latest_time_month 0.23536009610676906\n",
      "loans_latest_time_weekday 0.21550477980307856\n",
      "regional_mobility 0.20654433409120623\n",
      "is_high_user 0.19615128275454694\n",
      "avg_consume_less_12_valid_month 0.22239702810015521\n",
      "reg_preference_for_trad 0.2177870321526657\n",
      "consume_top_time_last_6_month 0.20011434179160154\n",
      "railway_consume_count_last_12_month 0.1961481366164229\n",
      "jewelry_consume_count_last_6_month 0.1961481366164229\n",
      "apply_credibility 0.21236457565886172\n",
      "query_org_count 0.20111878037869466\n",
      "loans_credibility_behavior 0.20913259783498153\n",
      "consfin_org_count_behavior 0.20557154838757058\n",
      "latest_one_month_loan 0.19737896713498773\n",
      "loans_credibility_limit 0.20533354487764222\n",
      "loans_product_count 0.21194036422792928\n",
      "consfin_org_count_current 0.20557154838757058\n",
      "consfin_product_count 0.20286887692642128\n"
     ]
    }
   ],
   "source": [
    "useless = []\n",
    "for feature in X_train.columns:\n",
    "    if feature in [t[1] for t in feature_impotance1[50:]] and feature in [t[1] for t in feature_impotance2[50:]]:\n",
    "        useless.append(feature)\n",
    "        print(feature, iv_dict[feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(useless, axis = 1, inplace = True)\n",
    "X_test.drop(useless, axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型选择与模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 特征归一化\n",
    "std = StandardScaler()\n",
    "X_train = std.fit_transform(X_train.values)\n",
    "X_test = std.transform(X_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "lr = LogisticRegression(C = 0.1, penalty = 'l1')\n",
    "svm_linear = svm.SVC(C = 0.01, kernel = 'linear', probability=True)\n",
    "svm_poly =  svm.SVC(C = 0.01, kernel = 'poly', probability=True)\n",
    "svm_rbf =  svm.SVC(gamma = 0.01, C =0.01 , probability=True)\n",
    "svm_sigmoid =  svm.SVC(C = 0.01, kernel = 'sigmoid',probability=True)\n",
    "dt = DecisionTreeClassifier(max_depth=5,min_samples_split=50,min_samples_leaf=60, max_features=9, random_state =2333)\n",
    "xgb = XGBClassifier(learning_rate =0.1, n_estimators=80, max_depth=3, min_child_weight=5, \n",
    "                    gamma=0.2, subsample=0.8, colsample_bytree=0.8, reg_alpha=1e-5, \n",
    "                    objective= 'binary:logistic', nthread=4,scale_pos_weight=1, seed=27)\n",
    "lgb = LGBMClassifier(learning_rate =0.1, n_estimators=100, max_depth=3, min_child_weight=11, \n",
    "                    gamma=0.1, subsample=0.5, colsample_bytree=0.9, reg_alpha=1e-5, \n",
    "                    nthread=4,scale_pos_weight=1, seed=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[准确率] 训练集： 0.8563 测试集： 0.8024\n",
      "[auc值] 训练集： 0.9026 测试集： 0.7909\n"
     ]
    }
   ],
   "source": [
    "sclf = StackingClassifier(classifiers=[svm_linear, svm_poly, svm_rbf, svm_sigmoid, dt, xgb, lgb], \n",
    "                            meta_classifier=lr, use_probas=True,average_probas=False)\n",
    "sclf.fit(X_train, y_train.values)\n",
    "model_metrics(sclf, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析：调参后单模型性能有所提升。Stacking后和未特征选择时的结果对比，相差不大（AUC略有下降）。\n",
    "\n",
    "起码说明，删除某些特征后，对性能影响不大 → 这些特征冗余。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
